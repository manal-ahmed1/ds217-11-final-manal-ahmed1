{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64cac424",
   "metadata": {},
   "source": [
    "# Q8: Results\n",
    "\n",
    "**Phase 9:** Results & Insights  \n",
    "**Points: 3 points**\n",
    "\n",
    "**Focus:** Generate final visualizations, create summary tables, document key findings.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 4 ([`11/demo/04_modeling_results.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/04_modeling_results.ipynb)), Phase 9. Also see Lecture 07 (visualization).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0537730",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/q7_model_metrics.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load model results from Q7\u001b[39;00m\n\u001b[1;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/q7_predictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput/q7_model_metrics.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     11\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/q7_feature_importance.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/HDS/Fall 2025/DATASCI217/ds217-11-final-manal-ahmed1/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/q7_model_metrics.txt'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load model results from Q7\n",
    "predictions = pd.read_csv('output/q7_predictions.csv')\n",
    "metrics = open('output/q7_model_metrics.txt').read()\n",
    "feature_importance = pd.read_csv('output/q7_feature_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c7560",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Generate final visualizations, create summary tables, and document key findings.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q8_final_visualizations.png`\n",
    "**Format:** PNG image file\n",
    "**Content:** Final summary visualizations\n",
    "**Required visualizations (at least 2 of these):**\n",
    "1. **Model performance comparison:** Bar plot or line plot comparing R², RMSE, or MAE across models\n",
    "2. **Predictions vs Actual:** Scatter plot showing predicted vs actual values (with perfect prediction line)\n",
    "3. **Feature importance:** Bar plot showing top N features by importance\n",
    "4. **Residuals plot:** Scatter plot of residuals (actual - predicted) vs predicted\n",
    "\n",
    "**Requirements:**\n",
    "- Clear axis labels (xlabel, ylabel)\n",
    "- Title for each subplot\n",
    "- Overall figure title (optional but recommended)\n",
    "- Legend if multiple series shown\n",
    "- Saved as PNG with sufficient resolution (dpi=150 or higher)\n",
    "\n",
    "### 2. `output/q8_summary.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Key findings summary table\n",
    "**Required columns:**\n",
    "- `Metric` - Metric name (e.g., \"R² Score\", \"RMSE\", \"MAE\")\n",
    "- One column per model (e.g., `Linear Regression`, `Random Forest`, `XGBoost`)\n",
    "\n",
    "**Requirements:**\n",
    "- Must include at least R², RMSE, MAE metrics\n",
    "- One row per metric\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "Metric,Linear Regression,Random Forest,XGBoost\n",
    "R² Score,-0.0201,0.9705,0.9967\n",
    "RMSE,12.7154,2.1634,0.7276\n",
    "MAE,9.8468,1.3545,0.4480\n",
    "```\n",
    "\n",
    "### 3. `output/q8_key_findings.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Text summary of main insights\n",
    "**Required information:**\n",
    "- Best performing model and why\n",
    "- Key findings from feature importance\n",
    "- Temporal patterns identified\n",
    "- Data quality summary\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "KEY FINDINGS SUMMARY\n",
    "===================\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Best performing model: XGBoost (R² = 0.9967)\n",
    "- All models show reasonable performance (R² > 0.7 for tree-based models)\n",
    "- XGBoost achieves lowest RMSE: 0.73°C\n",
    "\n",
    "FEATURE IMPORTANCE:\n",
    "- Most important feature: Air Temperature (importance: 0.6539)\n",
    "- Top 3 features account for 93.6% of total importance\n",
    "- Temporal features (hour, month) are highly important\n",
    "\n",
    "TEMPORAL PATTERNS:\n",
    "- Clear seasonal patterns in temperature data\n",
    "- Daily and monthly cycles are important predictors\n",
    "\n",
    "DATA QUALITY:\n",
    "- Dataset cleaned: 50,000 → 50,000 rows\n",
    "- Missing values handled via forward-fill and median imputation\n",
    "- Outliers capped using IQR method\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Final visualizations created (model performance, key insights)\n",
    "- [ ] Summary tables generated\n",
    "- [ ] Key findings documented\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Create visualizations** - Multi-panel figure with model comparison, predictions vs actual, feature importance, and/or residuals\n",
    "2. **Create summary table** - DataFrame with metrics as rows and models as columns\n",
    "3. **Document key findings** - Text summary covering model performance, feature importance insights, temporal patterns, and data quality notes\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Visualizations:** What best communicates your findings? Model performance plots? Time series with predictions? Feature importance plots?\n",
    "- **Summary:** What are the key takeaways? Document the most important findings from your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q8, you should have:\n",
    "- [ ] Final visualizations created (2+ plots)\n",
    "- [ ] Summary tables generated\n",
    "- [ ] Key findings documented\n",
    "- [ ] All 3 artifacts saved: `q8_final_visualizations.png`, `q8_summary.csv`, `q8_key_findings.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q9_writeup.md` for Writeup.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
