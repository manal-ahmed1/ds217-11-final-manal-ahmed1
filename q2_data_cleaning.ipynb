{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b3d469",
   "metadata": {},
   "source": [
    "# Q2: Data Cleaning\n",
    "\n",
    "**Phase 3:** Data Cleaning & Preprocessing  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Handle missing data, outliers, validate data types, remove duplicates.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 1 ([`11/demo/01_setup_exploration_cleaning.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/01_setup_exploration_cleaning.ipynb)), Phase 3. Also see Lecture 05 (data cleaning).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load data from Q1 (or directly from source)\n",
    "df = pd.read_csv('data/beach_sensors.csv')\n",
    "# If you saved cleaned data from Q1, you can load it:\n",
    "# df = pd.read_csv('output/q1_exploration.csv')  # This won't work - load original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6b0ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Clean the dataset by handling missing data, outliers, validating data types, and removing duplicates.\n",
    "\n",
    "**Time Series Note:** For time series data, forward-fill (`ffill()`) is often appropriate for missing values since sensor readings are continuous. However, you may choose other strategies based on your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q2_cleaned_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Cleaned dataset with same structure as original (same columns)\n",
    "**Requirements:**\n",
    "- Same columns as original dataset\n",
    "- Missing values handled (filled, dropped, or imputed)\n",
    "- Outliers handled (removed, capped, or transformed)\n",
    "- Data types validated and converted\n",
    "- Duplicates removed\n",
    "- **Sanity check:** Dataset should retain most rows after cleaning (at least 1,000 rows). If you're removing more than 50% of data, reconsider your strategy—imputation is usually preferable to dropping rows for this dataset.\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q2_cleaning_report.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Detailed report of cleaning operations\n",
    "**Required information:**\n",
    "- Rows before cleaning: [number]\n",
    "- Missing data handling method: [description]\n",
    "  - Which columns had missing data\n",
    "  - Method used (drop, forward-fill, impute, etc.)\n",
    "  - Number of values handled\n",
    "- Outlier handling: [description]\n",
    "  - Detection method (IQR, z-scores, domain knowledge)\n",
    "  - Which columns had outliers\n",
    "  - Method used (remove, cap, transform)\n",
    "  - Number of outliers handled\n",
    "- Duplicates removed: [number]\n",
    "- Data type conversions: [list any conversions]\n",
    "- Rows after cleaning: [number]\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Rows before cleaning: 50000\n",
    "\n",
    "Missing Data Handling:\n",
    "- Water Temperature: 2500 missing values (5.0%)\n",
    "  Method: Forward-fill (time series appropriate)\n",
    "  Result: All missing values filled\n",
    "  \n",
    "- Air Temperature: 1500 missing values (3.0%)\n",
    "  Method: Forward-fill, then median imputation for remaining\n",
    "  Result: All missing values filled\n",
    "\n",
    "Outlier Handling:\n",
    "- Water Temperature: Detected 500 outliers using IQR method (3×IQR)\n",
    "  Method: Capped at bounds [Q1 - 3×IQR, Q3 + 3×IQR]\n",
    "  Bounds: [-5.2, 35.8]\n",
    "  Result: 500 values capped\n",
    "\n",
    "Duplicates Removed: 0\n",
    "\n",
    "Data Type Conversions:\n",
    "- Measurement Timestamp: Converted to datetime64[ns]\n",
    "\n",
    "Rows after cleaning: 50000\n",
    "```\n",
    "\n",
    "### 3. `output/q2_rows_cleaned.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Single integer number (total rows after cleaning)\n",
    "**Requirements:**\n",
    "- Only the number, no text, no labels\n",
    "- No whitespace before or after\n",
    "- Example: `50000`\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Missing data handling strategy chosen and implemented\n",
    "- [ ] Outliers detected and handled (IQR method, z-scores, or domain knowledge)\n",
    "- [ ] Data types validated and converted\n",
    "- [ ] Duplicates identified and removed\n",
    "- [ ] Cleaning decisions documented in report\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Handle missing data** - Choose appropriate strategy (drop, forward-fill, impute) based on data characteristics\n",
    "2. **Detect and handle outliers** - Use IQR method or z-scores; decide whether to remove, cap, or transform\n",
    "3. **Validate data types** - Ensure numeric and datetime columns are properly typed\n",
    "4. **Remove duplicates**\n",
    "5. **Document and save** - Write detailed cleaning report explaining your decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Missing data:** Should you drop rows, impute values, or forward-fill? Consider: How much data is missing? Is it random or systematic? For time series, forward-fill is often appropriate.\n",
    "- **Outliers:** Are they errors or valid extreme values? Use IQR method or z-scores to detect, then decide: remove, cap, or transform. Document your reasoning.\n",
    "- **Data types:** Are numeric columns actually numeric? Are datetime columns properly formatted? Convert as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q2, you should have:\n",
    "- [ ] Missing data handled\n",
    "- [ ] Outliers addressed\n",
    "- [ ] Data types validated\n",
    "- [ ] Duplicates removed\n",
    "- [ ] All 3 artifacts saved: `q2_cleaned_data.csv`, `q2_cleaning_report.txt`, `q2_rows_cleaned.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q3_data_wrangling.md` for Data Wrangling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4a91b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if missing values occur in the same rows\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m cols_with_same_missing \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAir Temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWet Bulb Temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRain Intensity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Rain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecipitation Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBarometric Pressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeading\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m missing_mask \u001b[38;5;241m=\u001b[39m df_clean[cols_with_same_missing]\u001b[38;5;241m.\u001b[39misnull()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if missing values occur in the same rows\n",
    "df_clean = df.copy()\n",
    "\n",
    "cols_with_same_missing = ['Air Temperature', 'Wet Bulb Temperature', 'Rain Intensity', 'Total Rain', 'Precipitation Type', 'Barometric Pressure', 'Heading']\n",
    "missing_mask = df_clean[cols_with_same_missing].isnull()\n",
    "print(f\"Rows where ALL are missing: {missing_mask.all(axis=1).sum()}\")\n",
    "print(f\"Rows where ANY are missing: {missing_mask.any(axis=1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Air Temperature\"] = df_copy[\"Air Temperature\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Wet Bulb Temperature\"] = df_copy[\"Wet Bulb Temperature\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Rain Intensity\"] = df_copy[\"Rain Intensity\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Total Rain\"] = df_copy[\"Total Rain\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Precipitation Type\"] = df_copy[\"Precipitation Type\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Barometric Pressure\"] = df_copy[\"Barometric Pressure\"].fillna(method=\"ffill\")\n",
      "/var/folders/tl/bj19ztj54sl9lbx8m4r74x4r0000gq/T/ipykernel_9273/3451036732.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_copy[\"Heading\"] = df_copy[\"Heading\"].fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "#impute missing values using forward fill\n",
    "df_copy = df.copy()\n",
    "df_copy[\"Air Temperature\"] = df_copy[\"Air Temperature\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Wet Bulb Temperature\"] = df_copy[\"Wet Bulb Temperature\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Rain Intensity\"] = df_copy[\"Rain Intensity\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Total Rain\"] = df_copy[\"Total Rain\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Precipitation Type\"] = df_copy[\"Precipitation Type\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Barometric Pressure\"] = df_copy[\"Barometric Pressure\"].fillna(method=\"ffill\")\n",
    "df_copy[\"Heading\"] = df_copy[\"Heading\"].fillna(method=\"ffill\")\n",
    "\n",
    "\n",
    "#handle outliers\n",
    "num_cols = [\"Air Temperature\", \"Wet Bulb Temperature\",\"Humidity\", \n",
    "            \"Rain Intensity\",\"Interval Rain\", \"Total Rain\", \"Precipitation Type\",\n",
    "            \"Wind Direction\", \"Wind Speed\", \"Maximum Wind Speed\", \"Barometric Pressure\",\n",
    "            \"Solar Radiation\", \"Heading\", \"Battery Life\"]\n",
    "outlier_counts = {}\n",
    "for var in num_cols:\n",
    "    q1 = df_copy[var].quantile(0.25)\n",
    "    q3 = df_copy[var].quantile(0.75)\n",
    "    mid = q3 - q1\n",
    "    lb = q1 - 1.5 * mid\n",
    "    ub = q3 + 1.5 * mid\n",
    "    num_outliers = ((df_copy[var] < lb) | (df_copy[var] > ub)).sum()\n",
    "    outlier_counts[var] = num_outliers \n",
    "    df_copy[var] = np.where(\n",
    "        df_copy[var] > ub, ub,\n",
    "        np.where(df_copy[var] < lb, lb, df_copy[var])\n",
    "    )\n",
    "\n",
    "#check types\n",
    "df_copy[\"Measurement Timestamp\"] = pd.to_datetime(df_copy[\"Measurement Timestamp\"])\n",
    "\n",
    "map = {0: \"No Precipitation\", 60: \"Liquid Precipitation\", 70: \"Solid Precipitation\", 40: \"Unspecified Precipitation\"}\n",
    "df_copy[\"Precipitation Type\"] = df_copy[\"Precipitation Type\"].map(map).astype(\"category\")\n",
    "\n",
    "\n",
    "\n",
    "#remove duplicates\n",
    "df_copy = df_copy.drop_duplicates()\n",
    "\n",
    "df_copy.to_csv(\"output/q2_cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##FILE 2\n",
    "\n",
    "t1 = f\"Rows before cleaning: {df.shape[0]}\"\n",
    "t2 = \"Missing data handling method: used forward fill to impute all missing values.\"\n",
    "t3 = \"Air Temperature, Wet Bulb Temperature, Rain Intensity, Total Rain, Precipitation Type, Barometric Pressure, and Heading had missing data\"\n",
    "t4 = \"All but Air Temperature and Barometric Pressure had 75935 values that needed to be filled. Air Temperature had 75, and Barometric Pressure had 146.\"\n",
    "t5 = \"The outlier detection method used was IQR, and any values that were considered outliers were capped.\"\n",
    "t6 = f\"Columns and number of outliers before cleaning: {outlier_counts}\"\n",
    "t7 = \"0 duplicates found and removed\"\n",
    "t8 = \"Measurement Timestamp was made into a datetime variable, and Precipitation Type was made into a categorical variable.\"\n",
    "t9 = f\"Rows after cleaning: {df_copy.shape[0]}\"\n",
    "\n",
    "texts = [t1,t2,t3,t4,t5,t6,t7,t8,t9]\n",
    "texts = \"\\n\\n\".join(texts)\n",
    "with open(\"output/q2_cleaning_report.txt\", \"w\") as f:\n",
    "    f.write(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##FILE 3\n",
    "\n",
    "ret = df_copy.shape[0]\n",
    "with open(\"output/q2_rows_cleaned.txt\", \"w\") as f:\n",
    "    f.write(str(ret))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
